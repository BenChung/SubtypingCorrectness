\documentclass[a4paper,english]{lipics-v2019}
\usepackage{wrapfig,microtype,amssymb,amsmath,stmaryrd,mathpartir,array,graphicx,tabularx}
\usepackage[table]{xcolor}
\newcommand{\xt}[1]{\texttt{#1}}
%\newcommand{\tupleo}[1]{\xt{Tuple1\{}#1\xt{\}}}
\newcommand{\tuplet}[2]{\xt{Tuple\{}#1,#2\xt{\}}}
\newcommand{\union}[2]{\xt{Union\{}#1,#2\xt{\}}}
\newcommand{\denotes}[1]{\llbracket #1 \rrbracket}

%FZ
\newcommand{\sub}{<:}
\newcommand{\tuple}[1]{\xt{Tuple\{}#1\xt{\}}}
\newcommand{\arrayt}[1]{\xt{Array\{}#1\xt{\}}}
\newcommand{\FZ}[1]{\textbf{FZ says: #1}}
%end FZ

\newcommand{\goodcell}{\cellcolor{green!25}}
\newcommand{\badcell}{\cellcolor{red!25}}
\bibliographystyle{plainurl}% the recommnded bibstyle
\title{Julia's efficient algorithm for subtyping unions and covariant tuples}
\titlerunning{Subtyping union types and covariant tuples}

\author{Benjamin Chung}{Northeastern University}{}{}{}%mandato
\author{Francesco Zappa Nardelli}{INRIA}{}{}{}
\author{Jan Vitek}{Northeastern University \& Czech Technical University}{}{}{}

\authorrunning{B. Chung, F. Zappa Nardelli, J. Vitek}

\Copyright{Benjamin Chung, Francesco Zappa Nardelli, Jan Vitek}%mandatory, plea
\ccsdesc[500]{Theory of computation~Type theory}
% mandatory: Please choose ACM 2012 classifications from https://www.acm.org/publications/class-2012 or https://dl.acm.org/ccs/ccs_flat.cfm . E.g., cite as "General and reference $\rightarrow$ General literature" or \ccsdesc[100]{General and reference~General literature}. 

\keywords{Type systems, Subtyping, Union types}

%\hideLIPIcs

\lstset{
 language=caml,
 columns=[c]fixed,
 basicstyle=\small\ttfamily,
 keywordstyle=\bfseries,
 upquote=true,
 commentstyle=,
 breaklines=true,
 showstringspaces=false}

%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{John Q. Open and Joan R. Access}
\EventNoEds{2}
\EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
\EventShortTitle{ECOOP}
\EventAcronym{ECOOP}
\EventYear{2019}
\EventDate{December 24--27, 2016}
\EventLocation{Little Whinging, United Kingdom}
\EventLogo{}
\SeriesVolume{42}
\ArticleNo{23}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle
\begin{abstract}
  The Julia programming language supports multiple dispatch and provides a
  rich type annotation language to specify method applicability. When
  multiple methods are applicable for a given call, Julia relies on
  subtyping between method signatures to pick the method to invoke. Julia's
  subtyping algorithm is surprisingly complex, and deciding whether it is
  correct remains an open question. In this paper, we focus on a piece of
  the problem, the interaction between union types and covariant
  tuples. Previous work that addressed this particular combination of
  features did so by normalizing types to a disjunctive normal form
  ahead-of-time. Normalization is not practical due to space-explosion for
  complex type signatures and to interactions with other features of Julia's
  type system.  Our contribution is a description of the algorithm
  implemented in the Julia run-time system. This algorithm is immune to the
  space-explosion and expressiveness problems of standard algorithms.  We
  prove this algorithm correct and complete against a semantic-subtyping
  denotational model in Coq.
\end{abstract}

\section{Introduction}

Union types, originally introduced by Barbanera and Dezani-
Ciancaglini~\cite{barbanera1991intersection}, are increasingly being used in
mainstream languages. In some cases, as Julia~\cite{BezansonEKS17} or
TypeScript~\cite{typescript}, they are exposed at the source level. In
others, such as Hack~\cite{hack}, they are only used internally when
performing type inference. We describe a space-efficient technique for
computing subtyping between types in the presence of distributive unions.
Our motivation arises from the Julia programming language. In our previous
work on formalizing the Julia subtyping algorithm~\cite{DBLP:NardelliBPCBV18},
we succinctly summarized the subtyping relation but were unable to describe
the subtyping algorithm or prove it correct. Indeed, we found a number of bugs
and were left with some unresolved issues.

Julia's subtyping algorithm is an important part of its semantics. Julia is a
dynamically typed language where methods are annotated with type signatures to
enable multiple dispatch. During program execution, the Julia run-time system
must determine which method to invoke at each call site. It does so by finding
the most specific (according to subtyping) applicable (also based on
subtyping) method that applies for a given invocation. The following snippet
shows three method declarations for the multiplication operator.

\begin{lstlisting}
 *(x::Number, r::Range)  = range(x*first(r),...)
 *(x::Number, y::Number) = *(promote(x,y)...)
 *(x::T, y::T) where T <: Union{Signed,Unsigned} =  mul_int(x,y)
\end{lstlisting}

\noindent The first two methods implement, respectively, the case where a
range is multiplied by a number and generic numeric multiplication. The
third method invokes native multiplication when both arguments are either
signed or unsinged integers (but not a mix of signed and unsigned).

Method signatures in Julia can be quite complex, making subtyping
difficult. Julia offers programmers a rich type language, including nominal
single subtyping, union types, existential types, covariant tuples,
invariant parametric datatypes, and singleton types. These features are
widely used in libraries, but pose challenges for subtyping. The main source
of inspiration for the design of subtyping in Julia was semantic
subtyping~\cite{Frisch02,BezansonEKS17}, but the final design departs from
that intuitive understanding of types.

This paper documents our first steps towards proving the correctness of the
Julia subtyping algorithm. We focus on the interaction of two features: union
types and covariant tuples. In Julia, tuples are used to represent function
signatures (Julia does not record return types). They are covariant as a
function with more specific arguments is preferred to a more generic one.
Union types are used as shorthand to avoid having to write multiple
functions with the same body.

Rules for subtyping union types and covariant tuples have been known for a
long time. Based on Vouillon~\cite{Vouillon04}, the following is a typical
deductive system:

\vspace{-3mm}{\small\begin{mathpar}
\inferrule{t' \sub t \\ t'' \sub t}{\union{t'}{t''} \sub t}

\inferrule{t \sub t'}{t \sub \union{t'}{t''}}

\inferrule{t \sub t''}{t \sub \union{t'}{t''}}

\inferrule{t_1 \sub t'_1 \\ t_2 \sub t'_2}{\tuple{t_1, t_2} \sub \tuple{t'_1, t'_2}}
\end{mathpar}}
\vspace{-3mm}

\noindent While this rule system makes sense, it has a  surprising
property: it  does not match the intuition for subtyping. If we think
of types as sets of values, as made formal by semantic
subtyping~\cite{Pierce1991}, we would expect that a union type would be
analogous to a set theoretic union. Similarly, we would then expect that two
types would be subtypes if their equivalent sets of values were subsets.
Therefore, when a union type appears on the left-hand side of a subtype
judgment, then \emph{all} its components must be subtypes of the right-hand
side; when a union type appears on the right-hand side of a subtype judgment,
then there must \emph{exist} a component that is a supertype of the left-hand
side. However, the above system of rules violates these ideas. Consider the
following judgment:

%
\vspace{-3mm}{\small\[
\tuple{\union{t'}{t''}, t} \ \ \sub\ \ \union{\tuple{t', t}}{\tuple{t'', t}} 
\]}
\vspace{-3mm}
%

\noindent  Under a semantic semantics, this judgment should hold. We write the
set of values denoted by the type $t$ as {\small $\llbracket t \rrbracket$}.
The left hand side denotes the values {\small $\{\tuple{v',v''} ~|~ v' \in
\llbracket t' \rrbracket \cup \llbracket t'' \rrbracket \wedge v'' \in
\llbracket t \rrbracket\}$}, while the right hand side denotes {\small $\llbracket
\tuple{t', t} \rrbracket \cup \llbracket \tuple{t'', t} \rrbracket$}.
Obviously, the sets are the same. However, we cannot derive this relation from
the above rules. According to those rules, we must pick either {\small $t'$}
or {\small $t''$} for the right-hand union, ending up with either {\small
$\tuple{\union{t'}{t''}, t} \sub \tuple{t', t}$} or {\small
$\tuple{\union{t'}{t''}, t} \sub \tuple{t'', t}$}. In either case, the right
hand side is overspecialized and the judgment does not hold.

Early work, by Barbanera and Dezani-
Ciancaglini~\cite{barbanera1991intersection} and Pierce~\cite{Pierce1991} uses
normalization to decide distributive subtyping between union types, while
Vouillon~\cite{Vouillon04} does not handle distributivity. Normalization
entails rewriting all types into their disjunctive normal form (DNF), as
unions of union-free (or base) types, \emph{before} building the derivation. This lifts
all choices at unions up to the top level, avoiding the structural
entanglements that cause the above issue. The correctness of this rewriting
step is justified by the semantic-subtyping denotational
model~\cite{Frisch08}, and the resulting subtype algorithm can be proved both
correct and complete. However, this standard algorithm based on ahead-of-time
normalization has two major drawbacks.  

The first drawback is that the normalization can lead to \emph{exponentially
bigger} types. Real Julia code has types like the following~\cite{DBLP:NardelliBPCBV18}:

\begin{small}
\begin{verbatim}
 Tuple{Tuple{Union{Int64, Bool}, Union{String, Bool}, Union{String, Bool}, 
             Union{String, Bool}, Union{Int64, Bool}, Union{String, Bool}, 
             Union{String, Bool}, Union{String, Bool}, Union{String, Bool}, 
             Union{String, Bool}, Union{String, Bool}, Union{String, Bool}, 
             Union{String, Bool}, Union{String, Bool}, Union{String, Bool}}, Int64}
\end{verbatim}
\end{small}

\noindent The normal form for this type has 32,768 constituent base types, making it impractical
to store or to compute with.

The second drawback of normalisation is that it does not interact well with
other features of the Julia type system. For instance, Julia supports invariant
constructors, which are incompatible with union normalization. In Julia, all 
parametric types aside from tuples are invariant on their arguments. For example,
if we say that the type $\arrayt{\xt{Int}}$ is an array of ints, it would not
be a subtype of $\arrayt{\xt{Any}}$. This seemingly simple feature, in conjunction
with type variables, makes normalization ineffective as an algorithm for subtyping
in Julia.

Consider the type {\small \(\arrayt{\union{t'}{t''}}\)}. This type denotes the set
of arrays whose elements are either of type {\small $t'$} or {\small   $t''$}.
It would be incorrect to rewrite it as {\small
\(\union{\arrayt{t'}}{\arrayt{t''}}\)}, as this latter type denotes the set of
arrays whose elements are either all of type {\small $t'$} or all of type
{\small$t''$}. A weaker disjunctive normal form, only lifting union types
inside each invariant constructor, can circumvent this problem. However, doing
so only to reveals a deeper problem in the presence of both invariant
constructors and {existential types}. This is illustrated by the following judgment:

%
\vspace{-3mm}{\small\[
  \arrayt{\union{\tuple{t}}{\tuple{t'}}} \ \ <:\ \ \exists T\,.\, \arrayt{\tuple{T}}
\]}\vspace{-3mm}
%

\noindent This judgment holds if we set the existential {\small$T=\union{t}{t'}$}.
Since all types are in weak normal form, an algorithm based on the standard
system of judgment rules would strip off the array type constructors and proceed.
However, since type constructors are invariant on their arguments, it must first test
that the relation holds in the original order (e.g. that $\union{\tuple{t}}{\tuple{t}} <: \tuple{T}$) 
and in the reverse order (that $\tuple{T} <: \union{\tuple{t}}{\tuple{t'}}$). It is in
this combined check that we run into problems.

The original order subtype check can be concluded without issue, producing the
constraint on $T$ {\small$\union{t}{t'} <: T$}. However, this constraint on $T$ is 
stored for checking the reversed direction of subtyping, which is where the problems
arise. When we check the opposite subtype order, we end up having to prove that {\small$\tuple{T}<:\union{\tuple{t}}{\tuple{t'}}$} and in turn
either {\small$T<:t$} or {\small$T<:t'$}. All of these are unprovable
under the assumption that {\small$\union{t}{t'} <: T$}.

The key to derive a successful judgment for this relation is to rewrite the
right-to-left check into {\small$\tuple{T}<:\tuple{\union{t}{t'}}$}, which is
provable. This \emph{anti-normalisation} rewriting must be performed on
sub-judgments of the derivation, and to the best of our knowledge it is not
part of any subtype algorithm based on ahead-of-time disjunctive
normalisation. As a result, straightforward normalization, even to a relaxed
normal form, is incompatible with the full Julia type system.

In this paper we describe the key ideas used by the subtype algorithm
implemented in the Julia language to deal with union types and covariant
tuples. This strategy avoids both aforementioned problems, though we will
focus  on the way that it solves the space explosion issue. To avoid being
drawn in the vast complexity of Julia type algebra, we focus on a minimal
language featuring union types, covariant tuples, and literals. This tiny
language is expressive enough to highlight the decision strategy, and make
this implementation technique known to a wider audience.  While Julia
implementation shows that this technique extends, among others, to invariant
constructors and existential types~\cite{DBLP:NardelliBPCBV18}, we expect that
it can be leveraged in many other modern language designs. Additionally we
prove in Coq that the algorithm is correct and complete with respect to a
standard semantic subtyping model.


\section{A space-efficient subtyping algorithm}

This section presents a simplified version of Julia's subtype algorithm.  To
better align with our Coq proof, the algorithm is implemented in Ocaml.  For
clarity, we omit some optimizations (they are discussed at the end of the
section). We focus on a core type language composed of binary unions,
covariant binary tuples, and primitive types:

\begin{lstlisting}
type typ =
 | Prim of int
 | Tuple of typ * typ
 | Union of typ * typ
\end{lstlisting}

Prim types are singletons with respect to subtyping, and are ranged over by
\(p_1, ... p_n\).

\subsection{Overview}

Consider the following query:

\[
\union{ \tuple{p_1,p_2}}{\tuple{p_2,p_3}}  <:  \tuple{ \union{p_2}{p_1}, \union{p_3}{p_2}}
\]

Are these types subtypes? Under the semantic definition of subtyping, we need
to ensure that every value denoted on the left hand side is present on the
right. It is easy to decide the subset relation for primitive types and tuples, 
as each denotes a simple fixed set, but unions induce difficulty. Using normalization,
we can reduce subtyping between types using unions to repeated subtyping of tuples and
primitives by looking at each type as a list of its basic types.

To do so, we can write out in a list every union-less type we can make out of our original type.
For every union in the type under consideration, we can select ``which way'' it went, be it left
or right. We construct a list of normalized choices by taking every such choice and remembering
what types we ended up with. On the left hand side, the union of tuples gives us two clear
choices, while the right hand side gives us four:

\[
\begin{array}{r|l}
\text{LHS} & \text{RHS} \\
\hline
\text{l1:} \tuple{p_1,p_2} & \text{r1:} \tuple{p_2,p_3}\\
\text{l2:} \tuple{p_2,p_3} & \text{r2:} \tuple{p_2,p_2}\\
                    & \text{r3:} \tuple{p_1,p_3}\\
                    & \text{r4:} \tuple{p_1,p_2}\\
\end{array}
\]

Using these lists, we can decide semantic subtyping between these two
types. To do so, we need to check that for every element on the left-hand-side,
there is an element on the right-hand-side that is a supertype. We can 
see that l1 is a subtype of r4, and that l2 is a subtype of r1, so the
semantic subtyping relationship between these two types holds.

To decide subtyping algorithmically we follow the same principle. We
use two functions: allexists, which iterates through every left-hand-side
choice and calls the second function, exists, which finds a right-hand-side
type that is a supertype of the chosen left-hand-side type. Each function
holds as state a position within the sequence of tuples, and iterates through 
each list as required.

This algorithm works to decide subtyping; however, we needed to normalize
the types to lists of clauses first, which as previously mentioned can consume
considerable amounts of space. Instead of materializing the normalized forms
of each type we can iterate through the same space by walking over the
ASTs of the type terms. In this manner, we achieve the same effect---iteration
over all possible normalized forms---but without precomputing the list of normal forms.

We can view the current position in the list as state of an iterator.
Equivalently to ``position in normalized list'' as iterator state,
we can use ``choices within type AST'' as our state; in this representation,
we remember each choice made within the type AST (i.e. every union encountered), 
which then defines a specific term in the normalized equivalent of the original type.

Consider, for example,
\[
 \tuple{ \union{p_2}{p_1}, \union{p_3}{p_2}}
\]
The AST for this type is the following tree:

\includegraphics[scale=0.5]{figures-gen/exmp1.pdf}

We can recover the types in the normalized sequence from the choices made at
each union in this tree. Position 1 in the normalized list can be encoded as a
left choice at the first union, then a left choice at the second union. Using
the order over trees defined by an inorder depth-first traversal, we could
call this taking the first and second lefts, or left left, or LL for short.
Similarly, note that position 2 corresponds to taking the left choice at the
first union, then the right choice at the second, or equivalently LR, while
position 3 and 4 in the normalized list are equivalent to RL and RR,
respectively. Each letter in each of the string represents one choice point,
and we can reconstruct the list of normalized types purely from the strings of
choices made at unions in the AST.

This equivalence between indices into terms from normalization and choices in
the type tree is interesting. If we draw out each of the choices at unions that were made
for each of the normalized terms in the type trees, we can see a pattern. In the following,
we show the selected components of the type ASTs in blue, and the choice made at each union
as an L for a left choice and R for a right choice above and to the left of the node.

\begin{tabular}{r|c|c|c|c}
Normal type:&$\tuple{p_2,p_3}$&$\tuple{p_2,p_2}$&$\tuple{p_1,p_3}$&$\tuple{p_1,p_2}$\\
Index:&1 & 2 & 3 & 4\\
Tree:&\includegraphics[scale=0.35]{figures-gen/exmp2a.pdf} &
\includegraphics[scale=0.35]{figures-gen/exmp2b.pdf} &
\includegraphics[scale=0.35]{figures-gen/exmp2c.pdf} &
\includegraphics[scale=0.35]{figures-gen/exmp2d.pdf} \\
Equivalent list:&LL&LR&RL&RR
\end{tabular}

A pattern emerges! Each successive index into the list of
normal terms corresponds to a simple operation on the previous
choices at unions within the tree. To find the following normal 
term from the choices of the prior term, it suffices to find the
rightmost L-choice, turn it into a R-choice, and then replace all
of the remaining choices with L-choices. Instead of indexing into
the list of normal terms, our algorithm could instead perform this
tree operation.

We can exploit this pattern to let us iterate through the list of 
base types that we would otherwise need to get from normalization.
Iteration from one state to the next involves three key steps:
\begin{itemize}
\item Stepping, identifying the choice that needs to be updated.
\item Truncation, eliminating old and invalid choices.
\item Padding, inserting new choices so that the new type is fully defined.
\end{itemize}
These three phases are shown in figure~\ref{fig:sstep}, which depicts
a single evolution between the base types at indexes 2 and 3. 

The first phase of the evolution, stepping, identifies the \emph{last
alternative} choice that could be made within the type AST. Due to the
order of normalization, we want to try to move further right within the
AST; therefore, the stepping phase is trying to find the last L-choice
to make into a R-choice. When considering the linearized representation
of the choices on the tree, note that this is similar to incrementing a 
binary number. Where binary number increment tries to identify the last 0
to turn into a 1, the stepping phase identifies the last L-choice to turn
into an R-choice.

The second phase is truncation. Unlike a binary number, the maximum length of
a path depends on the choices made within that path and the structure of the
type AST. Changing a choice higher in the type AST then can invalidate  any
choices made later. If we consider, for example, the type
$\union{\union{p_1}{p_2}}{p_3}$, the choice lists LL, LR, and R are valid; RR is
not. To avoid this, we need to truncate the choices that follow the toggled
choice. In the example here, the choice list LR would evolve to R because the
list is truncated following the toggle of the first L to an R.

\begin{figure}
\centering
\begin{tabularx}{\linewidth}{c|ccc}
& Initial & Stepped & Padded\\
Subtree: &
\includegraphics[scale=0.50]{figures-gen/transex1.pdf} & 
\includegraphics[scale=0.50]{figures-gen/transex2.pdf} & 
\includegraphics[scale=0.50]{figures-gen/transex3.pdf} \\
Choice List: & \underline{L}R & \underline{R} & \underline{R}L \\
Effective Type: & \tuple{A,D} & \tuple{B,?} & \tuple{B,C} \\
\end{tabularx}
\caption{State-stepping operation for choice lists}
\label{fig:sstep}
\end{figure}

Finally, the third phase is padding. Truncating invalid types in the previous
phase may leave us with a set of choices that would include a union type in
the result. To avoid this, we need to insert new choices for whatever structure
remains in the type AST from our new position. Due to our iteration order of 
left-to-right, the new choices will be L-choices.

Based on this logic, we can also define an initial state: the all-L-choice
configuration. Using the same we traverse-left-to-right reasoning, it follows
that we should start in the leftmost possible configuration of all L-choices.
This can be accomplished by padding the empty list to conform to a given type
AST.


\noindent
\begin{minipage}{\textwidth}
\begin{minipage}{0.45\textwidth}
\begin{lstlisting}
type choice = Left | Right




let rec toggle = function
  | [] -> []    
  | Left::tl -> Right::tl
  | Right::tl -> toggle tl

let step (l:choice list) =
  let reversed = List.rev l in
  match List.rev (toggle reversed) with
  | [] -> None
  | hd::tl -> Some(hd::tl)
\end{lstlisting}
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{lstlisting}
let rec pad(a:typ)
           (l:choice list) = 
match (a,ls) with
 | (Prim i,_) -> ([],ls)
 | (Tuple(t1,t2) _) -> 
    let (hd,tl) = pad t1 ls in
    let (hd2,tl2) = pad t2 tl in
    (hd @ hd2,tl2)
 | (Union(l,r),Left::rs) -> 
   let (hd,tl) = pad l rs in 
   (Left::hd,tl)
 | (Union(l,r),Right::rs) -> 
   let (hd,tl) = pad r rs in 
   (Right::hd,tl)
 | (Union(l,r),[]) -> 
   (Left::initial l,[])
\end{lstlisting}
\end{minipage}

\begin{minipage}{0.96\textwidth}
\begin{lstlisting}
let rec next(a:typ)(l:choice list) =
  option_map fst (option_map (pad a) (step l))
\end{lstlisting}
\end{minipage}
\end{minipage}

To illustrate the implementation of this stepping system, we show its
implementation in OCaml above. The first two phases of the evolution are
implemented in the \lstinline{toggle} and \lstinline{step} functions, while
the padding phase is implemented in the \lstinline{pad} function.
\lstinline{toggle} and \lstinline{step} work by reversing the list, finding
the first L-choice, turning it into an R-choice, forgetting about all
predecessors, and reversing the list again. This toggles the last L-choice
(stepping) and deletes all subsequent choices (truncation). Padding in 
\lstinline{pad} is structural, and identifies the point at which the given
choice list runs out after which it will insert L-choices until it reaches a 
Prim. Finally, the overarching step function \lstinline{next} is the composition
of \lstinline{pad} and \lstinline{step}.

\subsection{Subtyping}

As discussed previously, it's easy to decide subtyping if given the normalized
form of both inputs. The algorithm loops through each of the base types on the
left looking for a supertype among the right-hand base types. The problem that
we described, however, was that in requiring the normalized form this
algorithm needs exponential space. However, armed with the abovementioned
iterator state, we can now use the same algorithm but without the space
explosion.

The idea is that instead of iterating through each list element by element
we can iterate using the structural iterators to represent the base types
being examined in each iteration. As long as the iterators are equivalent to
the lists of base types produced by normalization, the execution is identical.



Outline:

subtyping with normalization precomputes the lists of base types. then it checks
forall-exists between them. want to avoid precomputation

it's equivalent to use our iterators. thus we can iterate using the exact same
algortihm but without the memory overhead

algorithm in ocaml consists of a base subtyping relation and two nested iterations
over the left and right hand sides. the left hand iteration invokes the right hand
iteration, searching for a right element that is a supertype of the left element.
if all left elements have a right element which is a supertype, then subtyping holds.
if there is some left element such that all right elements are not a supertype then 
the types are not subtypes.

Endout.

Figure~\ref{fig:sstep} shows these two equivalent processes in detail,
depicting the transition between the second to the third normal type. In
the initial state, the tree form depicts us taking an L-choice at the first
union and an R-choice at the second union; equivalently, the linear representation
takes a L-choice than an R-choice. In the stepping operation, we notice that the
final choice is an R-choice, so we cannot step it further; we continue back and
identify that the first choice is an L-choice, so we turn it into an R-choice and
remove all following choices. However, we have not made a choice at all unions
anymore, as we no longer have a choice for the right union. To fix this, we make
the L-choice at every union without a defined choice, equivalent to padding out
the linearized representation with L-choices until it has a choice for every union.

To fully define this stepping function, we depict an implementation in OCaml.
It uses the linear representation of the choices made in a type AST, operating
over \lstinline{choice list}s and \lstinline{typ}s. A new iterator state may
be constructed by using the \lstinline{pad} function to pad out the empty
choice list with L-choices, making a L-choice for every union in the type.
Stepping then works in the same two phases as above; the \lstinline{next}
function first calls \lstinline{step}, which finds the final L-choice in the
list, turns it into an R-choice, and truncates all remaining choices. Then,
\lstinline{next} calls \lstinline{pad} to fill out the rest of the list with
L-choices to ensure that all unions have a choice. If no L-choices remain in
the list, \lstinline{step} will return \lstinline{None}, indicating that there
are no more normal types to explore in the type being iterated.



Through this mechanism, we have found two representations we can use as state
for an iterator that examines every normal type in the normalized form without
having to precompute them. It remains to use it to decide subtyping.

\subsection{Subtyping}

As discussed previously, we can decide subtyping by deciding if there is some
value denoted by the right hand side for every value denoted by the left. In
our type language, we accomplish this by finding one of the constituent base
types  on the right for each base type---a type without any unions---on the
left. The original subtyping algorithm  we proposed did this by normalizing
both sides to lists of their base type constituents, then using a base
subtyping relation to establish the  required relationship between said lists.
We aim to replace the normalization to a list of base types with iterators
that have the same meaning.

We can do this in a very straightforward way. Since we have demonstrated the
equivalence of iterating through possible choices within the type AST to
iterating through the arrays of base types produced by normalization, we can
use the exact same algorithm with only minor changes. As before, our algorithm
needs to find a supertype on the right for every base type on the left.


\begin{lstlisting}
type res =
 | IsSub of choice list * choice list
 | NotSub
\end{lstlisting}

\begin{lstlisting}
let rec sub(a:typ)(b:typ)(f:choice list)(e:choice list)
 match (a,b,f,e) with
 | (Prim i,Prim j,_,_) -> if i==j then IsSub(f,e) else NotSub
 | (Tuple(ta1,ta2), Tuple(tb1,tb2),_,_) ->
    (match sub ta1 tb1 f e with
     | IsSub(f', e') -> sub ta2 tb2 f' e'
     | NotSub -> NotSub)
 | (Union(a1,a2),b,d::f',e) -> 
       sub (match d with Left->a1 | Right->a2) b f' e
 | (a,Union(b1,b2),f,d::e') -> 
       sub a (match d with Left->b1 | Right->b2) f e'
\end{lstlisting}

The first ``trick'' that we take advantage of is the fact that we never need
to actually compute the base types we're subtyping. Instead, we can subtype
the original AST in the context of the choice lists for each side. This is
implemented in the above \lstinline{sub} function. It takes the full type ASTs
being subtyped as well as the forall (\lstinline{f}) and exists
(\lstinline{e}) choice lists, then computes subtying between the baes types 
implied by the given choices in the given type AST. It does so by using the 
given choice lists whenever it encounters a union, thereby eliminating all
unions from the types under consideration.



\begin{figure}[h]
\center
\begin{tabular}{cc|cc|c}
\multicolumn{2}{c}{Stack} & \multicolumn{2}{c}{Type} & Base Query \\
\hline
$\forall$ & $\exists$ & $\forall$ & $\exists$ & \\
\hline
\goodcell L & \goodcell L & \goodcell \includegraphics[scale=0.3]{figures-gen/left1.pdf} & \goodcell \includegraphics[scale=0.3]{figures-gen/right1.pdf} 
    & \goodcell ${A} <: {A}$ \\
\hline
\goodcell R & \badcell L & \badcell \includegraphics[scale=0.3]{figures-gen/left2.pdf} & \badcell \includegraphics[scale=0.3]{figures-gen/right1.pdf}  
    & \badcell ${B} \not<: {A}$ \\
\goodcell R & \goodcell R & \goodcell \includegraphics[scale=0.3]{figures-gen/left2.pdf} & \goodcell \includegraphics[scale=0.3]{figures-gen/right2.pdf}  
    & \goodcell ${B} <: {B}$ \\
\hline
\end{tabular}

\hspace{1em}

$\tuple{\union{A}{B}} <: \union{\tuple{A}}{\tuple{B}}$

\caption{Subtyping decision procedure example; should I continue to exist?}\label{fig:cfs}
\end{figure}

Armed with this, all that remains to decide subtyping in a space-efficient
manner is to compactly iterate over the choice lists. As described previously,
we need to iterate over every base type on the left (forall) and find if there
exists a supertype on the right (exists). We do this with two recursive
functions:


\begin{lstlisting}
let rec exists(a:typ)(b:typ)(f:choice list)(e:choice list) =
 match sub a b f e with 
  | IsSub(_,_) -> true 
  | NotSub -> 
     (match next b e with
      | Some ns -> exists a b f ns 
      | None -> false) 
\end{lstlisting}

 \begin{lstlisting}
let rec allexists(a:typ)(b:typ)(f:choice list) =
  match exists a b f (initial b) with 
  | true -> (match next a f with
             | Some ns -> allexists a b ns 
             | None -> true) 
  | false -> false
\end{lstlisting}


\begin{lstlisting}
let subtype(a:typ)(b:typ) = allexists a b (initial a)
\end{lstlisting}

Each of the functions \lstinline{exists} and \lstinline{allexists} implements
one ``side'' of the search. \lstinline{exists} is given a single left-hand choice 
list (and thus correspondant base type) and searches the right hand side's choice lists
to see if there is a supertype of the given left-hand type. \lstinline{allexists} iterates
through every type on the left using \lstinline{exists} to ensure that a supertype exists
on the right hand side. Finally, \lstinline{subtype} simply calls \lstinline{allexists} with
the initial iterator state.

In this manner, we can decide subtyping between types with distributive unions and tuples
without requiring ahead-of-time normalization. However, we have not yet shown that this
algorithm is correct, which will be the topic of the following section.

\subsection{Further optimizations}

We have presented our subtyping algorithm using lists of choices. In a
practical implementation, however, these lists of choices can be efficiently
implemented (without allocation) by means of bit sets. This is the approach
taken in the Julia implementation of this algorithm. With this optimization,
the needed memory to decide a subtyping judgment is linear in the total number
of unions in the given types; the algorithm needs no allocation beyond that
of the choice stacks themselves.

\section{Correctness and completeness}

To prove correctness of our algorithm, we begin by formally specifying
correctness for subtyping. We then show that two subtyping algorithms---
based on structural iterators and choice lists---are correct
with respect to this definition in Coq.

We base our definition of subtyping on a denotational semantics for types. 
We reduce types in the type language including unions to sets of types
in the type language without unions through a simple transformation. 

\begin{align*}
\denotes{\xt{A}} &= \{A\} \\
\denotes{\union{t_1}{t_2}} &= \denotes{t1} \cup \denotes{t2} \\
\denotes{\tuplet{t_1}{t_2}} &= \{\tuplet{t'_1}{t'_2} | t_1' \in \denotes{t_1},  t_2' \in \denotes{t_2'}\} \\
\end{align*}

Using this denotational semantics for types-with-unions, we can define
subtyping as if $\denotes{t_1} \subseteq \denotes{t_2}$, then $t_1 <: t_2$.
Equivalently, we can state this as definition~\ref{dfn:scr}, which is canonicalized
in our Coq proof as the \verb|NormalSubtype| relation.

\begin{definition}[Subtyping Correctness]
A subtyping relation $<:$ is correct if $t_1 <: t_2$ iff $\forall t_1' \in \denotes{t_1},
\exists t_2' \in \denotes{t_2}, t_1 <: t_2$.
\label{dfn:scr}
\end{definition}

Proving a subtyping algorithm sound and complete is therefore equivalent to
producing a function of type \verb|forall t1 t2:type, {NormalSubtype t1 t2} + {~NormalSubtype t1 t2}|; that is, is able to decide whether two types are
subtypes or not.

We will begin by describing and proving correct a version of the algorithm
that uses explicit type-structural iterators. We will then show the choice
stack-based algorithm correct by proving equivalence between structural
iterators and choice stacks. In doing so, we will derive an induction
principle for structural iterators (and, as an extension, for choice stacks).

\subsection{Iterators}

The Coq iterator-based implementation is directly equivalent (as will be shown
later) to the choice-stack based implementation presented previously in OCaml.
However, it retains type structure information inside of the iterator state.

\begin{small}\begin{verbatim}
Inductive TypeIterator: type -> Set :=
| TIPrim : forall i, TypeIterator (atom i)
| TITuple : forall t1 t2, TypeIterator t1 -> TypeIterator t2 -> TypeIterator (tuple t1 t2)
| TIUnionL : forall t1 t2, TypeIterator t1 -> TypeIterator (union t1 t2)
| TIUnionR : forall t1 t2, TypeIterator t2 -> TypeIterator (union t1 t2).
\end{verbatim}\end{small}

The \verb|TypeIterator| structure follows the structure of the type being
iterated over. Choices at unions are represented as either an instance of
\verb|TIUnionR| or \verb|TIUnionL|. This structure then lets us trivially
define a function that extracts the current type at the iterator's position:

\begin{small}\begin{verbatim}
Fixpoint current (t:type)(ti:TypeIterator t):type :=
match ti with
| TIPrim i => atom i
| TITuple ti1 ti2 p1 p2 => tuple (current ti1 p1) (current ti2 p2)
| TIUnionL ti1 ti2 pl => (current ti1 pl)
| TIUnionR ti1 ti2 pr => (current ti2 pr)
end.
\end{verbatim}
\end{small}

\noindent We can then define a function that produces the initial iterator state for a
given type:

\begin{small}
\begin{verbatim}
Fixpoint start_iterator (t:type):TypeIterator t :=
  match t with
  | (atom i) => TIPrim i
  | (tuple t1 t2) => TITuple t1 t2 (start_iterator t1) (start_iterator t2)
  | (union t1 t2) => TIUnionL t1 t2 (start_iterator t1)
  end.
\end{verbatim}
\end{small}

\noindent Next, we can define a step function that takes one state and either steps it
to the next state or indicates that no such next state exists.

\begin{small}\begin{verbatim}
Fixpoint next(t:type)(ti:TypeIterator t) : option (TypeIterator t) :=
  match ti with
  | TIPrim i => None
  | TITuple ti1 ti2 p1 p2 =>
    match (next ti2 p2) with
    | Some np2 => Some(TITuple ti1 ti2 p1 np2)
    | None =>
      match (next ti1 p1) with
      | Some np1 => Some(TITuple ti1 ti2 np1 (start_iterator ti2))
      | None => None
      end
    end
  | TIUnionL ti1 ti2 pl =>
    match (next ti1 pl) with
    | Some npl => Some(TIUnionL ti1 ti2 npl)
    | None => Some(TIUnionR ti1 ti2 (start_iterator ti2))
    end
  | TIUnionR ti1 ti2 pr => option_map (TIUnionR ti1 ti2) (next ti2 pr)
  end.
\end{verbatim}\end{small}

With these definitions, we can then prove a basic form of correctness with
respect to the denotational or normalization semantics:

\begin{theorem}[Correctness of iterators]\begin{verbatim}
Remaining t (start_iterator t) (clauses t)
\end{verbatim}
Every type in $\denotes{t}$ will be explored using \verb|next_step| from \verb|start_iterator t|. 
\end{theorem}
\begin{proof}
The \verb|Remaining| predicate relates iterators to the list of types that remain to be iterated, so
the Coq theorem statement indicates that the initial state of the iterator for type $t$ has every clause
in the normalized version of $t$ remaining to be iterated.

We proceed by induction on $t$. The cases for atomic types and unions follow
from the IH trivially. We prove the theorem for tuples correct by case analyzing
on the number of clauses induced by the first element in the tuple, then identifying
the next element produced by the iterator from the tuple.

See \verb|iterator_has_clauses| in the Coq proof for full details.
\end{proof}

\verb|next| returns \verb|Some s| if there is some successor state
\verb|s| to the current, and \verb|None| if the given iterator state is
terminal. It will go left-to-right through unions, and will explore 2-tuples
by iterating through the choices on the right for each choice on the left. We can
then define an induction principle for type iterators based on \verb|next|:

\begin{theorem}
\begin{small}\begin{verbatim}
Definition iter_rect
  (t:type) (P:TypeIterator t -> Set)
           (pi: forall it, next t it = None -> P it)
           (ps : forall it' it'', P it'' -> next t it' = Some it'' -> P it')
           (it : TypeIterator t) : P it  
\end{verbatim}\end{small}

For any type \verb|t| and proposition \verb|P|, and if:
\begin{itemize} 
	\item \verb|P| holds for an iterator that has no next state (e.g. is done)
	\item if \verb|P| holds for the \emph{following} iterator state \verb|it|,
	then \verb|P| holds for the \emph{preceeding} iterator state \verb|it'|.
\end{itemize}
Then \verb|P| holds for all iterators for type \verb|t|
\end{theorem}
\begin{proof}
Proving the induction principle for type iterators relies on the \verb|iternum|
function, which decides the number of steps remaining in the iterator before termination.
The proof proceeds by simultaneous case analysis on the number of remaining states and
whether the iterator step function can produce a successor state from the present state.

If the iteration number is not yet 0, and if there is a successor state, then
we simply  appeal to the induction hypothesis and continue on. If there is no
successor state but  the iteration number is nonzero or vice versa, then by
lemma (\verb|iternum_monotonic|, taking an iterator step decrements the
iteration number) contradiction. Finally, if there is no next step and the iteration
number is 0, then we have reached the base case and terminate.

For full details, see the Coq definition of \verb|iter_rect|.
\end{proof}

Using \verb|iter_rect|, we can implement and prove correct equivalent functions
to \verb|exists|, \verb|allexists|, and \verb|subtype| as described in the
OCaml implementation.

\begin{small}\begin{verbatim}
Definition exists_iter(a b : type) : 
  ({ t | InType t b /\ BaseSubtype a t } +
   {forall t, InType t b -> ~(BaseSubtype a t) }).
\end{verbatim}\end{small}

\verb|exists_iter| is equivalent to the choice-stack based \verb|exists|,
and determines if there exists some denotationally-contained type in \verb|b|
that is a supertype of the given \verb|a|. Internally, it is implemented in 
the same way as \verb|exists|, though using \verb|iter_rect| to iterate 
through every iterator state.

\begin{small}\begin{verbatim}
Definition forall_iter (a b : type) :
  { forall t, In t (clauses a) -> exists t', InType t' b /\ (BaseSubtype t t')} +
  { exists t, In t (clauses a) /\ forall t', InType t' b -> ~ (BaseSubtype t t')}.
\end{verbatim}\end{small}

\verb|forall_iter| is to \verb|allexists| what \verb|exists_iter| is to
\verb|exists|. Like \verb|exists_iter| it implements the same decision procedure
as \verb|allexists| (and internally relies upon \verb|exists_iter|), though through
the abstraction of \verb|iter_rect|.

Finally, we can define a decidable function (called \verb|subtype| in the proof)
that decides whether two types are subtypes or not. \verb|subtype| simply invokes
\verb|forall_iter| to decide subtyping.

\begin{small}\begin{verbatim}
Definition subtype(a b:type) : {NormalSubtype a b} + {~NormalSubtype a b}.
  destruct (forall_iter a b).
  - left. [...]
  - right. [...]
Defined.
\end{verbatim}\end{small}

\noindent Therefore, using iterators, we can decide whether subtyping holds for any two types
in our language. We will now show an equivalence between iterators and stacks-of-choices,
allowing for more efficient implementation.

\subsection{Stacks}

To show that the choice-stack based algorithm is correct, we reduce it to the
already-shown-correct iterator-based algorithm for deciding subtyping. To do so,
we show an equivalence between choice stacks and iterators, then prove correctness
of the subtyping algorithms.

In the context of the Coq proof, we use the type \verb|st_context| to refer
to a choice stack. In Coq, this is represented as a list of boolean values,
with false representing a left choice and true representing a right choice at
a specific union.

To show equivalence between the iterator-based and stack-based algorithm, we need to
first prove two properties:

\begin{itemize}
  \item iterators are convertible to equivalent choice lists;
  \item stepping an iterator is equivalent to stepping a choice list.
\end{itemize}

We define an iterator and a choice stack to be equivalent if, when applied to
the same type, they select the same subset of that type. To describe this, we
define \verb|lookup_path| which looks up what type is selected by a given
choice stack.

\begin{small}\begin{verbatim}
Fixpoint lookup_path(t:type)(p:st_context) : type * st_context :=
  match t, p with
  | atom i, _ => (t, p)
  | tuple t1 t2, _ =>
    let (r1,p1) := lookup_path t1 p in
    let (r2,p2) := lookup_path t2 p1 in
    (tuple r1 r2, p2)
  | union l r, false::rs => lookup_path l rs
  | union l r, true::rs => lookup_path r rs
  | _, nil => (t, nil)
  end.
\end{verbatim}\end{small}

\verb|lookup_path| is notable in that it both returns the selected type as
well as whatever of the choice stack remains once it reaches a leaf. This is
needed in order to be able to traverse types that contain tuples,  whose left
branches will potentially be given a longer choice stack then necessary.

Next, we can convert iterators to paths in the straightforward manner, as
implemented by \verb|iterator_to_path|:

\begin{small}\begin{verbatim}
Fixpoint iterator_to_path(t:type)(it:TypeIterator t):st_context :=
   match it with
   | TIPrim _ => nil
   | TITuple t1 t2 it1 it2 => (iterator_to_path t1 it1) ++ (iterator_to_path t2 it2)
   | TIUnionL t1 _ it1 => false :: (iterator_to_path t1 it1)
   | TIUnionR _ t2 it1 => true :: (iterator_to_path t2 it1)
   end.
\end{verbatim}\end{small}

\verb|iterator_to_path| simply traverses the iterator in order, appending onto the
output choice stack whatever choice the iterator makes at that union. This illustrates
the equivalence between iterators and choice stacks; choice stacks are simply iterators
with the structural information removed.

Using the combination of \verb|lookup_path| and \verb|iterator_to_path|, we
can then show the first correctness property that we need to prove that the
algorithm using choice stacks is correct:

\begin{lemma}[Iterator to path is correct]
\begin{small}\begin{verbatim}
Lemma itp_correct : forall t it, 
  current t it = fst (lookup_path t (iterator_to_path t it)).
\end{verbatim}\end{small}

For every type \verb|t| and type iterator \verb|it|, the iterator's current type \verb|current t it| is equal
to the result of looking up the conversion of \verb|it| to a choice stack.
\end{lemma}
\begin{proof}
See \verb|itp_correct| in the Coq proof.
\end{proof}

Stepping in the Coq implementation is implemented identically to the OCaml
implementation. It only remains to show that this step operation (called
\verb|step_ctx| in Coq) is correct with respect to the iterator
\verb|next|.

\begin{lemma}[Correctness of step\_ctx]
\begin{small}\begin{verbatim}
forall t it,
    step_ctx t (iterator_to_path t it) =
    (option_map (iterator_to_path t) (next t it)).
\end{verbatim}\end{small}
For every type \verb|t| and type iterator \verb|it|,
stepping the choice-list equivalent of \verb|it| will
produce the same result as converting the result of stepping
\verb|it|.
\end{lemma}
\begin{proof}
See \verb|list_step_correct| in the Coq proof.
\end{proof}

Now, with the relevant properties proven, we can implement and prove correct
\verb|exists| and \verb|allexists| in Coq. The function names are the
same, as are the implementations up to the addition of a fuel parameter (which
is shown to be unnecessary). 

\begin{lemma}[Correctness of existential subtype checking with choice stacks]
\begin{small}\begin{verbatim}
forall a b it, 
  (exists pf, exists_iter_inner a b it = inleft pf) <->
   exists n, exists a b (iterator_to_path b it) n = Some true.
\end{verbatim}\end{small}
For every two types \verb|a| and \verb|b|, the iterator-based algorithm
\verb|exists_iter_inner| will produce a proof that \verb|a| is a subtype
of \verb|b| if and only if there is an integer \verb|n| such that
 \verb|exists| given \verb|n| fuel runs producing true.
\end{lemma}
\begin{proof}
See \verb|ex_sub_corr_eq| in the Coq proof.
\end{proof}

\begin{lemma}[Correctness of forall-exists subtype checking with choice stacks]
\begin{small}\begin{verbatim}
forall a b it,
   (exists pf, forall_iter_inner a b it = left pf) <->
    exists n, allexists a b (iterator_to_path a it) n = Some true.
\end{verbatim}
\end{small}  
For every two types \verb|a| and \verb|b|, the iterator-based algorithm
\verb|forall_iter_inner| will produce a proof that \verb|a| is a subtype
of \verb|b| if and only if there is an integer \verb|n| such that
 \verb|allexists| given \verb|n| fuel runs producing true.
\end{lemma}
\begin{proof}
See \verb|fa_sub_corr_eq| in the Coq proof.
\end{proof}

The choice stack-based algorithm therefore is provably equivalent to the
iterator-based algorithm, and is thus correct.

\section{Performance Analysis}

The algorithm improves upon normalization in two key ways:
\begin{itemize}
  \item lazily exploring possible clauses, obviating the need to store a fully normalized type;
  \item enabling fast paths that avoid the exploration of the full choice space.
\end{itemize}

In the worst case, our algorithm has the same big-O time complexity. However,
lazily exploring the choice space allows us to require worst-case polynomial
space, in comparison to normalization's exponential space complexity.
Similarly, the algorithm enables optimizations that offer best (and typical)
case time complexity improvements from exponential to linear time.

Worst case time complexity of both subtyping algorithms is determined by the
number of clauses that would exist in the normalized type. In the worst case,
(a tuple of unions), each union begets a different clause in the normalized
type. Consider $\tuple{\union{A}{B}, \union{C}{D}}$, which will normalize to
$\union{\tuple{A,C}}{\tuple{A, D}, \tuple{B, C}, \tuple{B, D}}$ generating a 
new tuple for each choice for every contained union. As a result, there are
worst-case $2^n$ tuples in the fully normalized version of a type that has $n$
unions.

In order to ensure correctness, each of these tuples (or choices at unions)
must always be explored. As a result, both the algorithm we present here and
normalization will have worst-case $O(2^n)$ time complexity. The approaches
differ, however, in space complexity. The normalization approach computes and
stores each of the exponentially many alternatives, so also has $O(2^n)$ space
complexity. However, the algorithm we discuss need only store the choice made
at each union, thereby offering $O(n)$ space complexity.

The algorithm we discuss also can improve best-case time performance.
Normalization will necessarily be $o(2^n)$ due to computation of the entire
normalized type. However, the lazy subtyping algorithm need only make one
choice before discovering that a subtype relation exists in the best-case,
giving $o(n)$ performance. Moreover, computing type choices lazily enables
fast-paths to short circuit full exploration of choice alternatives.

This is important for Julia due to a common programming idiom. Many Julia
library developers write signatures of the form $\tuple{\union{A}{B},
\union{C}{D}}$ to indicate that their method can take any of the named
types. When deciding dispatch against these methods, Julia will frequently
check if a tuple containing solely concrete (instantiable) types is a subtype 
of the tuple of unions. If Julia used normalization, this would always be 
exponential on the number of unions that appeared in the argument list as this
is the above mentioned worst-case exponential complexity case. However, its use
of the lazy algorithm enables it frequently identify the best alternative and
short circuit before having to explore much of the choice possibility space.

\section{Conclusion}

We have presented an algorithm for deciding subtyping relationships between
types that consist of atomic types, tuples, and unions. This algorithm is able
to decide subtyping relationships in the presence of distributive semantics
for union types without needing normalization (and therefore using linear
space) and without additionally constraining type system features.

\subsubsection*{Acknowledgments}
The authors thank Jiahao Chen for starting us down the path of understanding
Julia, and Jeff Bezanson for coming up with Julia's subtyping algorithm.  This
work received funding from the European Research Council under the European
Union's Horizon 2020 research and innovation programme (grant agreement
695412), the NSF (award 1544542 and award 1518844) and the Czech Ministry of
Education, Youth and Sports (grant agreement
CZ.02.1.01/0.0/0.0/15\_003/0000421).
 

%\bibliographystyle{plain}
\bibliography{refs}
\end{document}
